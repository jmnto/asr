{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/\"\n",
    "\n",
    "# Input: Folder Path\n",
    "# Output: Tuple (Label, Indices of the labels, one-hot encoded labels)\n",
    "def get_labels(path=DATA_PATH):\n",
    "    labels = os.listdir(path)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "    return labels, label_indices, to_categorical(label_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "\n",
    "print( to_categorical(np.arange(0, len(os.listdir(DATA_PATH)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handy function to convert wav2mfcc\n",
    "def wav2mfcc(file_path, max_len=11):\n",
    "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "    wave = wave[::3]\n",
    "    mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
    "\n",
    "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
    "    if (max_len > mfcc.shape[1]):\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    # Else cutoff the remaining parts\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    \n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wave, sr = librosa.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_data_to_array(path=DATA_PATH, max_pad_len=11):\n",
    "    labels, _, _ = get_labels(path)\n",
    "\n",
    "    for label in labels:\n",
    "        # Init mfcc vectors\n",
    "        mfcc_vectors = []\n",
    "\n",
    "        wavfiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "        for wavfile in wavfiles:\n",
    "            mfcc = wav2mfcc(wavfile, max_len=max_pad_len)\n",
    "            mfcc_vectors.append(mfcc)\n",
    "        np.save(label + '.npy', mfcc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/cat/6f689791_nohash_0.wav\n"
     ]
    }
   ],
   "source": [
    "path=DATA_PATH\n",
    "\n",
    "max_pad_len=11\n",
    "\n",
    "labels, _, _ = get_labels(path)\n",
    "\n",
    "label = labels[0]\n",
    "\n",
    "wavfiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "print(wavfiles[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_test(split_ratio=0.6, random_state=42):\n",
    "    # Get available labels\n",
    "    labels, indices, _ = get_labels(DATA_PATH)\n",
    "\n",
    "    # Getting first arrays\n",
    "    X = np.load(labels[0] + '.npy')\n",
    "    y = np.zeros(X.shape[0])\n",
    "\n",
    "    # Append all of the dataset into one single array, same goes for y\n",
    "    for i, label in enumerate(labels[1:]):\n",
    "        x = np.load(label + '.npy')\n",
    "        X = np.vstack((X, x))\n",
    "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
    "\n",
    "    assert X.shape[0] == len(y)\n",
    "\n",
    "    return train_test_split(X, y, test_size= (1 - split_ratio), random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "labels, indices, _ = get_labels(DATA_PATH)\n",
    "\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(path=DATA_PATH):\n",
    "    labels, _, _ = get_labels(path)\n",
    "    data = {}\n",
    "    for label in labels:\n",
    "        data[label] = {}\n",
    "        data[label]['path'] = [path  + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "\n",
    "        vectors = []\n",
    "\n",
    "        for wavfile in data[label]['path']:\n",
    "            wave, sr = librosa.load(wavfile, mono=True, sr=None)\n",
    "            # Downsampling\n",
    "            wave = wave[::3]\n",
    "            mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
    "            vectors.append(mfcc)\n",
    "\n",
    "        data[label]['mfcc'] = vectors\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(path=DATA_PATH):\n",
    "    data = prepare_dataset(path)\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    for key in data:\n",
    "        for mfcc in data[key]['mfcc']:\n",
    "            dataset.append((key, mfcc))\n",
    "\n",
    "    return dataset[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = prepare_dataset(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second dimension of the feature is dim2\n",
    "feature_dim_2 = 11\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_pad_len=feature_dim_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmnt/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full(1713, 1) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/home/jmnt/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full(1742, 2) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# # Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature dimension\n",
    "feature_dim_1 = 20\n",
    "channel = 1\n",
    "epochs = 50\n",
    "batch_size = 100\n",
    "verbose = 1\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshaping to perform 2D convolution\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " ..., \n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicts one sample\n",
    "def predict(filepath, model):\n",
    "    sample = wav2mfcc(filepath)\n",
    "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
    "    return get_labels()[0][\n",
    "            np.argmax(model.predict(sample_reshaped))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3112 samples, validate on 2076 samples\n",
      "Epoch 1/50\n",
      "3112/3112 [==============================] - 6s - loss: 1.6734 - acc: 0.4026 - val_loss: 0.9867 - val_acc: 0.4494\n",
      "Epoch 2/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.9539 - acc: 0.5504 - val_loss: 0.7903 - val_acc: 0.6180\n",
      "Epoch 3/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.7691 - acc: 0.6726 - val_loss: 0.5492 - val_acc: 0.8198\n",
      "Epoch 4/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.6146 - acc: 0.7548 - val_loss: 0.6156 - val_acc: 0.7620\n",
      "Epoch 5/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.5616 - acc: 0.7760 - val_loss: 0.4355 - val_acc: 0.8348\n",
      "Epoch 6/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.4891 - acc: 0.8123 - val_loss: 0.4677 - val_acc: 0.8112\n",
      "Epoch 7/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.4352 - acc: 0.8400 - val_loss: 0.3549 - val_acc: 0.8704\n",
      "Epoch 8/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.4076 - acc: 0.8490 - val_loss: 0.3165 - val_acc: 0.8887\n",
      "Epoch 9/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.3669 - acc: 0.8560 - val_loss: 0.3114 - val_acc: 0.8887\n",
      "Epoch 10/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.3145 - acc: 0.8869 - val_loss: 0.2924 - val_acc: 0.8984\n",
      "Epoch 11/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.2825 - acc: 0.8914 - val_loss: 0.2625 - val_acc: 0.9051\n",
      "Epoch 12/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.2653 - acc: 0.9017 - val_loss: 0.2668 - val_acc: 0.9066\n",
      "Epoch 13/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.2273 - acc: 0.9229 - val_loss: 0.3363 - val_acc: 0.8757\n",
      "Epoch 14/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.2158 - acc: 0.9242 - val_loss: 0.2363 - val_acc: 0.9171\n",
      "Epoch 15/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.2066 - acc: 0.9245 - val_loss: 0.2241 - val_acc: 0.9210\n",
      "Epoch 16/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.1774 - acc: 0.9351 - val_loss: 0.2145 - val_acc: 0.9210\n",
      "Epoch 17/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.1598 - acc: 0.9454 - val_loss: 0.2681 - val_acc: 0.9085\n",
      "Epoch 18/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.1538 - acc: 0.9454 - val_loss: 0.2466 - val_acc: 0.9162\n",
      "Epoch 19/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.1392 - acc: 0.9521 - val_loss: 0.2713 - val_acc: 0.9215\n",
      "Epoch 20/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.1310 - acc: 0.9550 - val_loss: 0.2239 - val_acc: 0.9205\n",
      "Epoch 21/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.1136 - acc: 0.9618 - val_loss: 0.2026 - val_acc: 0.9335\n",
      "Epoch 22/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.1086 - acc: 0.9640 - val_loss: 0.2038 - val_acc: 0.9330\n",
      "Epoch 23/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.1083 - acc: 0.9634 - val_loss: 0.2260 - val_acc: 0.9273\n",
      "Epoch 24/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.0862 - acc: 0.9704 - val_loss: 0.2262 - val_acc: 0.9316\n",
      "Epoch 25/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.0866 - acc: 0.9688 - val_loss: 0.2143 - val_acc: 0.9374\n",
      "Epoch 26/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.0717 - acc: 0.9727 - val_loss: 0.2022 - val_acc: 0.9383\n",
      "Epoch 27/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.0718 - acc: 0.9769 - val_loss: 0.2695 - val_acc: 0.9186\n",
      "Epoch 28/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.0778 - acc: 0.9746 - val_loss: 0.1978 - val_acc: 0.9403\n",
      "Epoch 29/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.0551 - acc: 0.9833 - val_loss: 0.2335 - val_acc: 0.9335\n",
      "Epoch 30/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.0534 - acc: 0.9843 - val_loss: 0.2084 - val_acc: 0.9398\n",
      "Epoch 31/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.0545 - acc: 0.9814 - val_loss: 0.2066 - val_acc: 0.9417\n",
      "Epoch 32/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.0459 - acc: 0.9846 - val_loss: 0.2240 - val_acc: 0.9359\n",
      "Epoch 33/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.0484 - acc: 0.9849 - val_loss: 0.2192 - val_acc: 0.9393\n",
      "Epoch 34/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.0431 - acc: 0.9865 - val_loss: 0.2608 - val_acc: 0.9330\n",
      "Epoch 35/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.0433 - acc: 0.9868 - val_loss: 0.2737 - val_acc: 0.9302\n",
      "Epoch 36/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.0370 - acc: 0.9878 - val_loss: 0.2358 - val_acc: 0.9408\n",
      "Epoch 37/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.0398 - acc: 0.9865 - val_loss: 0.2634 - val_acc: 0.9369\n",
      "Epoch 38/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.0378 - acc: 0.9865 - val_loss: 0.2116 - val_acc: 0.9480\n",
      "Epoch 39/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.0278 - acc: 0.9900 - val_loss: 0.2216 - val_acc: 0.9451\n",
      "Epoch 40/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.0262 - acc: 0.9894 - val_loss: 0.2276 - val_acc: 0.9422\n",
      "Epoch 41/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.0214 - acc: 0.9923 - val_loss: 0.2323 - val_acc: 0.9461\n",
      "Epoch 42/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.0306 - acc: 0.9878 - val_loss: 0.2480 - val_acc: 0.9383\n",
      "Epoch 43/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.0302 - acc: 0.9904 - val_loss: 0.2689 - val_acc: 0.9403\n",
      "Epoch 44/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.0235 - acc: 0.9933 - val_loss: 0.2974 - val_acc: 0.9321\n",
      "Epoch 45/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.0218 - acc: 0.9926 - val_loss: 0.2505 - val_acc: 0.9432\n",
      "Epoch 46/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.0220 - acc: 0.9916 - val_loss: 0.2378 - val_acc: 0.9427\n",
      "Epoch 47/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.0168 - acc: 0.9949 - val_loss: 0.2541 - val_acc: 0.9412\n",
      "Epoch 48/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.0165 - acc: 0.9942 - val_loss: 0.3743 - val_acc: 0.9263\n",
      "Epoch 49/50\n",
      "3112/3112 [==============================] - 4s - loss: 0.0241 - acc: 0.9929 - val_loss: 0.2512 - val_acc: 0.9432\n",
      "Epoch 50/50\n",
      "3112/3112 [==============================] - 5s - loss: 0.0209 - acc: 0.9933 - val_loss: 0.3185 - val_acc: 0.9340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbbdbdb6390>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed\n"
     ]
    }
   ],
   "source": [
    "print(predict('./data/bed/004ae714_nohash_1.wav', model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
